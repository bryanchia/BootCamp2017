{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Set 3 for OSM \n",
    "\n",
    "### Dynamic Programming with John Stachurski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the [OSM](https://bfi.uchicago.edu/osm) bootcamp dynamic programming section.\n",
    "\n",
    "We will use the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quantecon as qe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "\n",
    "Using Numba, as discussed in [this lecture](https://lectures.quantecon.org/py/need_for_speed.html), write your own version of NumPy's [interp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.interp.html) function, specializing in linear interpolation in one dimension.  \n",
    "\n",
    "Note that NumPy's function is compiled native machine code and hence is fast.  But try to beat if you can, at least in some scenarios, by using Numba to speed up your code.  Show a time comparison between the two functions, for some suitable choice of test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My code:\n",
      "TOC: Elapsed: 0.0011289119720458984 seconds.\n",
      "Jit code:\n",
      "TOC: Elapsed: 1.33925199508667 seconds.\n",
      "Their code:\n",
      "TOC: Elapsed: 0.0001399517059326172 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0001399517059326172"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import jit\n",
    "import inspect\n",
    "from numpy import interp\n",
    "#print(inspect.getsource(interp))\n",
    "from scipy.stats import linregress\n",
    "\n",
    "@jit\n",
    "def interp_numba(x, grid, w):\n",
    "    \n",
    "    #Sort x values that we are given & create a column that goes along with it for y\n",
    "    \n",
    "    y = np.empty_like(x)\n",
    "        \n",
    "    #Calculate point-slope formula for each set \n",
    "    slope = np.zeros(len(grid))\n",
    "    intercept = np.zeros(len(grid))\n",
    "        \n",
    "    for i in range(0, len(grid) - 1):\n",
    "        reg = linregress([grid[i],grid[i+1]], [w[i],w[i+1]])\n",
    "        slope[i] = reg[0]\n",
    "        intercept[i] = reg[1]\n",
    "            \n",
    "    #Find where each x value falls into \n",
    "        \n",
    "    place = np.searchsorted(grid, x)\n",
    "    \n",
    "    #Based on each x, find out the y using point slope formula\n",
    "        \n",
    "    for k in range (0, len(x)):\n",
    "            \n",
    "        if place[k] == 0:\n",
    "            y[k] = w[0]\n",
    "               \n",
    "        elif place[k] == len(grid):\n",
    "            y[k] = w[len(w) - 1]\n",
    "            \n",
    "        else:\n",
    "            y[k] = intercept[int(place[k]) - 1] + slope[int(place[k]) - 1] * float(x[k])\n",
    "    \n",
    "    return y\n",
    "\n",
    "@jit\n",
    "def getslope(grid, w):\n",
    "         \n",
    "    slope = np.zeros(len(grid))\n",
    "    intercept = np.zeros(len(grid))\n",
    "    \n",
    "    for i in range(0, len(grid) - 1):\n",
    "        \n",
    "        reg = linregress([grid[i],grid[i+1]], [w[i],w[i+1]])\n",
    "        slope[i] = reg[0]\n",
    "        intercept[i] = reg[1]\n",
    "    \n",
    "    return slope, intercept\n",
    "\n",
    "@jit\n",
    "def findy(x, grid, w, place, intercept, slope):\n",
    "    \n",
    "    for k in range (0, len(x)):\n",
    "            \n",
    "        if place[k] == 0:\n",
    "            y[k] = w[0]\n",
    "               \n",
    "        elif place[k] == len(grid):\n",
    "            y[k] = w[len(w) - 1]\n",
    "            \n",
    "        else:\n",
    "            y[k] = intercept[int(place[k]) - 1] + slope[int(place[k]) - 1] * float(x[k])    \n",
    "    \n",
    "    return y\n",
    "\n",
    "@jit\n",
    "def interp_numba_jit(x, grid, w):\n",
    "    \n",
    "    y = np.empty_like(x)\n",
    "    \n",
    "    slope, intercept = getslope(grid, w)\n",
    "        \n",
    "    place = np.searchsorted(grid, x)\n",
    "    \n",
    "    y = findy(x, grid, w, place, intercept, slope)\n",
    "    \n",
    "    return y\n",
    "\n",
    "print(\"My code:\")\n",
    "qe.util.tic()\n",
    "y = interp_numba([0,2,8,4,6], [1,3,5,7], [13, -5, 6, 7])\n",
    "qe.util.toc()\n",
    "\n",
    "print(\"Jit code:\")\n",
    "qe.util.tic()\n",
    "y = interp_numba_jit([0,2,8,4,6], [1,3,5,7], [13, -5, 6, 7])\n",
    "qe.util.toc()\n",
    "\n",
    "print(\"Their code:\")\n",
    "qe.util.tic()\n",
    "y = np.interp([0,2,8,4,6], [1,3,5,7], [13, -5, 6, 7])\n",
    "qe.util.toc()\n",
    "\n",
    "# Just want to say that I tried a couple of different things to get the Numba to make my code run faster but for some reason it won't.\n",
    "# I would love to just get some feedback I guess about what I am doing wrong with this code that I have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Using your \"Numbafied\" linear interpolation function, try to use Numba to additionally speed up the endogenous grid method code from [this lecture](https://lectures.quantecon.org/py/egm_policy_iter.html).  Use CRRA utility and Cobb-Douglas production, as in that lecture, with the following parameter values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I didn't get much speed up.  I think because the outer loops don't matter much for speed, and hence it doesn't gain us much when we compile them.  \n",
    "\n",
    "See how you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing policy function iteration with endogenous grid\n",
      "TOC: Elapsed: 0.14974188804626465 seconds.\n",
      "Timing policy function iteration with endogenous grid & numba\n",
      "TOC: Elapsed: 83.75886917114258 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.75886917114258"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def coleman_egm(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks):\n",
    "    \"\"\"\n",
    "    The approximate Coleman operator, updated using the endogenous grid\n",
    "    method.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g : function\n",
    "        The current guess of the policy function\n",
    "    k_grid : array_like(float, ndim=1)\n",
    "        The set of *exogenous* grid points, for capital k = y - c\n",
    "    beta : scalar\n",
    "        The discount factor\n",
    "    u_prime : function\n",
    "        The derivative u'(c) of the utility function\n",
    "    u_prime_inv : function\n",
    "        The inverse of u' (which exists by assumption)\n",
    "    f : function\n",
    "        The production function f(k)\n",
    "    f_prime : function\n",
    "        The derivative f'(k)\n",
    "    shocks : numpy array\n",
    "        An array of draws from the shock, for Monte Carlo integration (to\n",
    "        compute expectations).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate memory for value of consumption on endogenous grid points\n",
    "    c = np.empty_like(k_grid)  \n",
    "\n",
    "    # Solve for updated consumption value\n",
    "    for i, k in enumerate(k_grid):\n",
    "        vals = u_prime(g(f(k) * shocks)) * f_prime(k) * shocks\n",
    "        c[i] = u_prime_inv(beta * np.mean(vals))\n",
    "    \n",
    "    # Determine endogenous grid\n",
    "    y = k_grid + c  # y_i = k_i + c_i\n",
    "\n",
    "    # Update policy function and return\n",
    "    Kg = lambda x: np.interp(x, y, c)\n",
    "    return Kg\n",
    "\n",
    "def coleman_egm_numba(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks):\n",
    "    \"\"\"\n",
    "    The approximate Coleman operator, updated using the endogenous grid\n",
    "    method.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g : function\n",
    "        The current guess of the policy function\n",
    "    k_grid : array_like(float, ndim=1)\n",
    "        The set of *exogenous* grid points, for capital k = y - c\n",
    "    beta : scalar\n",
    "        The discount factor\n",
    "    u_prime : function\n",
    "        The derivative u'(c) of the utility function\n",
    "    u_prime_inv : function\n",
    "        The inverse of u' (which exists by assumption)\n",
    "    f : function\n",
    "        The production function f(k)\n",
    "    f_prime : function\n",
    "        The derivative f'(k)\n",
    "    shocks : numpy array\n",
    "        An array of draws from the shock, for Monte Carlo integration (to\n",
    "        compute expectations).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Allocate memory for value of consumption on endogenous grid points\n",
    "    c = np.empty_like(k_grid)  \n",
    "\n",
    "    # Solve for updated consumption value\n",
    "    for i, k in enumerate(k_grid):\n",
    "        vals = u_prime(g(f(k) * shocks)) * f_prime(k) * shocks\n",
    "        c[i] = u_prime_inv(beta * np.mean(vals))\n",
    "    \n",
    "    # Determine endogenous grid\n",
    "    y = k_grid + c  # y_i = k_i + c_i\n",
    "\n",
    "    # Update policy function and return\n",
    "    Kg = lambda x: interp_numba(x, y, c)\n",
    "    return Kg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import quantecon as qe\n",
    "\n",
    "class LogLinearOG:\n",
    "    \"\"\"\n",
    "    Log linear optimal growth model, with log utility, CD production and\n",
    "    multiplicative lognormal shock, so that\n",
    "\n",
    "        y = f(k, z) = z k^alpha\n",
    "\n",
    "    with z ~ LN(mu, s).\n",
    "\n",
    "    The class holds parameters and true value and policy functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.4, beta=0.96, mu=0, s=0.1):\n",
    "\n",
    "        self.alpha, self.beta, self.mu, self.s = alpha, beta, mu, s \n",
    "\n",
    "        # == Some useful constants == #\n",
    "        self.ab = alpha * beta\n",
    "        self.c1 = np.log(1 - self.ab) / (1 - beta)\n",
    "        self.c2 = (mu + alpha * np.log(self.ab)) / (1 - alpha)\n",
    "        self.c3 = 1 / (1 - beta)\n",
    "        self.c4 = 1 / (1 - self.ab)\n",
    "\n",
    "    def u(self, c):\n",
    "        \" Utility \"\n",
    "        return np.log(c)\n",
    "\n",
    "    def u_prime(self, c):\n",
    "        return 1 / c\n",
    "\n",
    "    def f(self, k):\n",
    "        \" Deterministic part of production function.  \"\n",
    "        return k**self.alpha\n",
    "\n",
    "    def f_prime(self, k):\n",
    "        return self.alpha * k**(self.alpha - 1)\n",
    "\n",
    "    def c_star(self, y):\n",
    "        \" True optimal policy.  \"\n",
    "        return (1 - self.alpha * self.beta) * y\n",
    "\n",
    "    def v_star(self, y):\n",
    "        \" True value function. \"\n",
    "        return self.c1 + self.c2 * (self.c3 - self.c4) + self.c4 * np.log(y)\n",
    "    \n",
    "lg = LogLinearOG()\n",
    "\n",
    "# == Unpack parameters / functions for convenience == #\n",
    "alpha, beta, mu, s = lg.alpha, lg.beta, lg.mu, lg.s\n",
    "v_star, c_star = lg.v_star, lg.c_star\n",
    "u, u_prime, f, f_prime = lg.u, lg.u_prime, lg.f, lg.f_prime\n",
    "\n",
    "grid_max = 4         # Largest grid point, exogenous grid\n",
    "grid_size = 200      # Number of grid points\n",
    "shock_size = 250     # Number of shock draws in Monte Carlo integral\n",
    "\n",
    "k_grid = np.linspace(1e-5, grid_max, grid_size)\n",
    "shocks = np.exp(mu + s * np.random.randn(shock_size))\n",
    "\n",
    "alpha = 0.65\n",
    "beta = 0.95\n",
    "mu = 0\n",
    "s = 0.1\n",
    "grid_min = 1e-6\n",
    "grid_max = 4\n",
    "grid_size = 200\n",
    "shock_size = 250\n",
    "\n",
    "gamma = 1.5   # Preference parameter\n",
    "gamma_inv = 1 / gamma\n",
    "\n",
    "def f(k):\n",
    "    return k**alpha\n",
    "\n",
    "def f_prime(k):\n",
    "    return alpha * k**(alpha - 1)\n",
    "\n",
    "def u(c):\n",
    "    return (c**(1 - gamma) - 1) / (1 - gamma)\n",
    "\n",
    "def u_prime(c):\n",
    "    return c**(-gamma)\n",
    "\n",
    "def u_prime_inv(c):\n",
    "    return c**(-gamma_inv)\n",
    "\n",
    "k_grid = np.linspace(grid_min, grid_max, grid_size)\n",
    "shocks = np.exp(mu + s * np.random.randn(shock_size))\n",
    "\n",
    "## Let's make convenience functions based around these primitives\n",
    "\n",
    "def crra_coleman_egm(g):\n",
    "    return coleman_egm(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks)\n",
    "\n",
    "def crra_coleman_egm_numba(g):\n",
    "    return coleman_egm_numba(g, k_grid, beta, u_prime, u_prime_inv, f, f_prime, shocks)\n",
    "\n",
    "sim_length = 20\n",
    "\n",
    "print(\"Timing policy function iteration with endogenous grid\")\n",
    "g_init_egm = lambda x: x\n",
    "g = g_init_egm\n",
    "qe.util.tic()\n",
    "for i in range(sim_length):\n",
    "    new_g = crra_coleman_egm(g)\n",
    "    g = new_g\n",
    "qe.util.toc()\n",
    "\n",
    "print(\"Timing policy function iteration with endogenous grid & numba\")\n",
    "g_init_egm = lambda x: x\n",
    "g = g_init_egm\n",
    "qe.util.tic()\n",
    "for i in range(sim_length):\n",
    "    new_g = crra_coleman_egm_numba(g)\n",
    "    g = new_g\n",
    "qe.util.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
